/// Don't delete any field from the schema once released.
/// Asign a id for each filed to keep compatibility easily.

// The below definitions of Record and RecordBatch are inspired by Kafka's protocols
table RecordBatchMeta {
    /// The stream id of this record batch.
    stream_id: int64 (id: 0);
    /// The record format version of this record batch.
    magic: byte (id: 1);
    /// The flags of this record batch. Each bit is used to indicate a specific flag.
    flags: short (id: 2);
    /// The base offset of the batch record, also is the logical offset of the first record.
    base_offset: int64 (id: 3);
    /// The delta value between the last offset and the base offset.
    last_offset_delta: int32 (id: 4);
    /// The create timestap of the first record in this batch.
    base_timestamp: int64 (id: 5);
}

table KeyValue {
    key: string (id: 0);
    value: string (id: 1);
}

table RecordMeta {
    offset_delta: int32 (id: 0);
    timestamp_delta: int32 (id: 1);
    headers: [KeyValue] (id: 2);
    properties: [KeyValue] (id: 3);
}